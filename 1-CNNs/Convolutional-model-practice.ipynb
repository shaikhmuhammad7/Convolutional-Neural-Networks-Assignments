{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80572878",
   "metadata": {},
   "source": [
    "# Building components of the convolutional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c7f6dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f00da2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(X, pad):\n",
    "    \"\"\"\n",
    "    Applies zero padding to the input X\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input\n",
    "    pad -- padding size\n",
    "    \n",
    "    Returns:\n",
    "    X_pad -- padded input\n",
    "    \"\"\"\n",
    "    \n",
    "    X_pad = np.pad(X, ((0, 0), (pad, pad), (pad, pad), (0, 0)))\n",
    "    \n",
    "    return X_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdd53dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3, 3, 2) (4, 5, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "x = np.random.randn(4, 3, 3, 2)\n",
    "x_padded = zero_pad(X=x, pad=1)\n",
    "print(x.shape, x_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2fca54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_single_step(a_slice_prev, W, b):\n",
    "    \"\"\"\n",
    "    Apply a single filter defined by parameters W on a single slice of the output activation of the previous layer.\n",
    "    \n",
    "    Arguments:\n",
    "    a_slice_prev -- slice of input data\n",
    "    W -- Weight parameters contained in a window \n",
    "    b -- Bias parameters contained in a window\n",
    "    \n",
    "    Returns:\n",
    "    Z -- Output of Convolution operation\n",
    "    \"\"\"\n",
    "    \n",
    "    s = np.multiply(a_slice_prev, W)\n",
    "    Z = np.sum(s)\n",
    "    b = np.squeeze(b)\n",
    "    Z = Z + b\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "826020af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.999089450680221\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "np.random.seed(1)\n",
    "a_slice_prev = np.random.randn(4, 4, 3)\n",
    "W = np.random.randn(4, 4, 3)\n",
    "b = np.random.randn(1, 1, 1)\n",
    "\n",
    "Z = conv_single_step(a_slice_prev, W, b)\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e93eae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward(A_prev, W, b, h_p):\n",
    "    \"\"\"\n",
    "    Arguements:\n",
    "    A_prev -- Previous activation layer or input X\n",
    "    W -- Weights\n",
    "    b -- biases\n",
    "    h_p -- hyperparameters (stride and pad)\n",
    "    \n",
    "    Returns:\n",
    "    Z, cache -- Convolved activation and cache for back propagation\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the shape of the previous activation \n",
    "    (m, n_HP, n_WP, n_CP) = A_prev.shape\n",
    "    \n",
    "    # Retrieve the shape of the kernel size\n",
    "    (f, f, n_CP, n_C) = W.shape\n",
    "    \n",
    "    # Retrieve the values for stride and padding from h_p dictionary\n",
    "    stride  = h_p['stride']\n",
    "    pad = h_p['pad']\n",
    "    \n",
    "    # Convolution output size calculation\n",
    "    n_H = int((n_HP + 2*pad - f)/stride) + 1\n",
    "    n_W = int((n_WP + 2*pad - f)/stride) + 1\n",
    "    \n",
    "    # Initialize output Z with zeros\n",
    "    Z = np.zeros((m, n_H, n_W, n_C))\n",
    "    \n",
    "    # Pad previous activation layer\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    \n",
    "    for i in range(m):\n",
    "        \n",
    "        # Takes the entire i'th example\n",
    "        a_prev_pad = A_prev_pad[i]\n",
    "        \n",
    "        for h in range(n_H):\n",
    "            # Generate windows for the slices of the activation/input X\n",
    "            vert_start = stride * h\n",
    "            vert_end = vert_start + f\n",
    "            \n",
    "            for w in range(n_W):\n",
    "                # Generate windows for the slices of the activation/input X\n",
    "                horiz_start = stride * w\n",
    "                horiz_end = horiz_start + f\n",
    "                \n",
    "                for c in range(n_C):\n",
    "                    \n",
    "                    # Take the slice with all of its channels\n",
    "                    a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                    \n",
    "                    # Take the weights and biases of the kernel/filter for each respective channel\n",
    "                    weights = W[:, :, :, c]\n",
    "                    biases = b[:, :, :, c]\n",
    "                    \n",
    "                    # Perform the convolution operation\n",
    "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, weights, biases)\n",
    "                    \n",
    "    cache = (A_prev, W, b, h_p)\n",
    "    \n",
    "    return Z, cache\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5c39c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5511276474566768"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity Check\n",
    "np.random.seed(1)\n",
    "h_p = {'stride':2, 'pad':1}\n",
    "A_prev = np.random.randn(2, 5, 7, 4)\n",
    "W = np.random.randn(3, 3, 4, 8)\n",
    "# 8 values for the bias parameters as there are 8 filters\n",
    "b = np.random.randn(1, 1, 1, 8)\n",
    "Z, cache_conv = conv_forward(A_prev, W, b, h_p)\n",
    "np.mean(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab351c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_forward(A_prev, h_p, mode = 'max'):\n",
    "    \"\"\"\n",
    "    Arguements:\n",
    "    A_prev -- Previous activation layer or input X\n",
    "    h_p -- hyperparameters (stride and filter_size)\n",
    "    \n",
    "    Returns:\n",
    "    A, cache -- Pooled activation and cache for back propagation\n",
    "    \"\"\"\n",
    "    \n",
    "    (m, n_HP, n_WP, n_CP) = A_prev.shape\n",
    "    \n",
    "    f = h_p['f']\n",
    "    stride = h_p['stride']\n",
    "    \n",
    "    n_H = int(1 + (n_HP - f) / stride)\n",
    "    n_W = int(1 + (n_WP - f) / stride)\n",
    "    n_C = n_CP\n",
    "    \n",
    "    A = np.zeros((m, n_H, n_W, n_C))\n",
    "    \n",
    "    for i in range(m):\n",
    "        a_prev_slice = A_prev[i]\n",
    "        \n",
    "        for h in range(n_H):\n",
    "            vert_start = stride * h\n",
    "            vert_end = vert_start + f\n",
    "            \n",
    "            for w in range(n_W):\n",
    "                horiz_start = stride * w\n",
    "                horiz_end = horiz_start + f\n",
    "                \n",
    "                for c in range(n_C):\n",
    "                    \n",
    "                    a_slice_prev = a_prev_slice[vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                    \n",
    "                    if mode == 'max':\n",
    "                        A[i, h, w, c] = np.max(a_slice_prev)\n",
    "                    elif mode == 'average':\n",
    "                        A[i, h, w, c] = np.mean(a_slice_prev)\n",
    "                    else:\n",
    "                        print(mode + \"-type pooling layer not Defined\")\n",
    "    \n",
    "    cache = (A_prev, h_p)\n",
    "    \n",
    "    assert(A.shape == (m, n_H, n_W, n_C))\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "807ae92d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 3, 3) [[1.96710175 0.84616065 1.27375593]\n",
      " [1.96710175 0.84616065 1.23616403]\n",
      " [1.62765075 1.12141771 1.2245077 ]]\n",
      "(2, 3, 3, 3) [[ 0.44497696 -0.00261695 -0.31040307]\n",
      " [ 0.50811474 -0.23493734 -0.23961183]\n",
      " [ 0.11872677  0.17255229 -0.22112197]]\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(2, 5, 5, 3)\n",
    "h_p = {'stride': 1, 'f': 3}\n",
    "\n",
    "A, cache = pool_forward(A_prev, h_p, mode = 'max')\n",
    "print(A.shape, A[1, 1])\n",
    "\n",
    "A, cache = pool_forward(A_prev, h_p, mode = 'average')\n",
    "print(A.shape, A[1, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
